import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.datasets import imdb
#(train_data, train_label), (test_data, test_label) = imdb.load_data(num_words = 10000)
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)
data = np.concatenate((X_train, X_test), axis=0) # axis 0 is first running vertically downwards across

label = np.concatenate((y_train, y_test), axis=0)
print('Review is ',X_train[0])
y_train

y_test


import numpy as np

def vectorize_sequences(sequences, dimensions = 10000):
  results = np.zeros((len(sequences), dimensions))
  for i,sequences in enumerate(sequences):
    results[i, sequences] = 1
  return results

x_train = vectorize_sequences(X_train)
y_train = vectorize_sequences(X_test)
y_train = np.asarray(y_train).astype('float32')
y_test = np.asarray(y_test).astype('float32')
     

from keras.models import Sequential
from keras.layers import Dense

# model = Sequential()
# model.add(Dense(16, input_shape=(10000, ), activation = "relu"))
# model.add(Dense(16, activation = "relu"))
# model.add(Dense(1, activation = "sigmoid"))
model = Sequential([Dense(16, input_shape=(10000, ), activation = "relu"),
        Dense(16, activation = "relu"),
        Dense(1, activation = "sigmoid")
                    ])
model.compile(optimizer='adam', loss = 'mse', metrics = ['accuracy'])
model.summary()
     
history = model.fit(x_train, y_train, validation_split = 0.3, epochs = 10, verbose = 1, batch_size = 512)
history.history 
#history object holds a record of the loss values and metric values during training: